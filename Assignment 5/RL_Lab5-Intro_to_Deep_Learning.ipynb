{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Introduction to Deep Learning\n",
    "\n",
    "This is an important lab session which aims to develop intuition for Deep Reinforcement Learning(DRL). \n",
    "For those familiar with Deep Learning(DL), you'll get to brush up some concepts. For those unfamiliar with this lab session it will be crash course of DL.\n",
    "\n",
    "We'll use PyTorch, a popular tool for upcoming DRL lab sessions. \n",
    "Please go through jupyter notebooks in oder.\n",
    "\n",
    "Technically you should have PyTorch installed from Lab 1, but incase you missed it you can install locally with.\n",
    "`pip install -r requirements.txt --user`\n",
    "\n",
    "After going through the Notebooks and getting a hang of the way PyTorch works, we will ask you to play around with the hyperparameters to fine-tune and techniques you can use to greatly improve your network's performance, and get a better intuition for the how and why it works.\n",
    "\n",
    "Please read the notebook chronologically, and fill in the **TODO**s as you encounter them.\n",
    "* <span style=\"color:blue\"> Blue **TODOs** </span> means you have to implement the TODOs in the code.\n",
    "* <span style=\"color:red\"> Red **TODOs** </span> means you have to submit an explanation (of graph/results).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Linear regression\n",
    "In linear regression, the relationships are modeled using linear functions whose unknown model parameters are estimated from the data. <br> We'll play around with a popular dataset of wine. <br> In dataset based on multiple features you'll determine the quality of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('winequality-red.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how it looks actually, other popular way to do is calling the head() function. Please refer to pandas for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes dataset can be too huge to display, the shape comes in handy to check how your dataset looks, <br> in current example there are 1599 rows and 12 columns. <br> When working with image dataset the shape maybe in channels like RGB and number of images or 1 channel if it's black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with stastical problems describe can give you quick insights. (here it's just to show you some functionalities of pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real world data is not as clean as this one, **ALWAYS KNOW YOUR DATA** . We check here just in case if there are null values that we may have to remove or fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining your data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[features].values\n",
    "y = dataset['quality'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would want to see the distribution of data so we know how imbalanced it is. you can read a lot about imbalance in detail. **It's good and bad ;)** Here we we'll contine playing with this imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(dataset['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just plot how these 3 features varry for different classes. If you are a wine lover you'll probably know this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = sns.pairplot(dataset, vars=['fixed acidity','volatile acidity','citric acid'], hue='quality')\n",
    "plt.show(relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop and think why do we have train and test set. If you don't know contact any of the teaching assistant to explain you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINALLY** <br> in this example we just used default parameters. you can have fun with them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from just estimating a function linear regression has lot many uses. It's one of the favorate tools used in reporting. We are just trying to explain the relation of a wine with different features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, features, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how you performed shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will you be able to explain the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we report common matrices i.e how close we can predict to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Decision Tree\n",
    "You can choose to read more about them here (https://en.wikipedia.org/wiki/Decision_tree) but in short they are like flowchart where you get the final class based on features. Decisions and their possible consequences are because of your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop('quality',axis=1)\n",
    "y = dataset['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTre = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clfTre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utfall = np.count_nonzero(clfTre.predict(X_test) == y_test)\n",
    "print(\"The decision tree predicts the test data in\", utfall/(len(X_test))*100 , \"% of the cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **TODO** </span> Are we performing better or worst compared to Linear regression? If worst, what can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Random Forest\n",
    "Random forests or random decision forests are an ensemble method. They are a form of decision tree, except they construct multitude of decision trees at training time and output the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utfall = np.count_nonzero(rf.predict(X_test) == y_test)\n",
    "print(\"The decision tree predicts the test data in\", utfall/(len(X_test))*100 , \"% of the cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Multi Layer Perceptron(MLP)\n",
    "\n",
    "A multilayer perceptron (MLP) is a class of feed forward artificial neural network (ANN). Multilayer perceptrons are sometimes colloquially referred to as \"vanilla\" neural networks, especially when they have a single hidden layer.\n",
    "\n",
    "<!-- ![image.png](attachment:image.png)\n",
    " -->\n",
    "<img src=https://scikit-learn.org/stable/_images/multilayerperceptron_network.png alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "[Image source](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    "\n",
    "The above image shows one hidden layer MLP with scaler output \n",
    "\n",
    "\n",
    "Most of the following can be visualized beforehand on a toy problem using the [Tensorflow Playground](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2&seed=0.35230&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false).\n",
    "\n",
    "On this playground, you can change the inputs, depth and width of the network, learning rate, task and noise, activation function, regularizer, batch size. We very strongly recommend you give it some time to play around, as it is excellent to build an intuition and understand the impact of all the choices the NN designer makes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture\n",
    "Three main choices can be made about an MLP's architecture:\n",
    "* *depth*: number of hidden layers\n",
    "* *width*: number of neurons in each layer\n",
    "* *non-linearity*: activation functions\n",
    "\n",
    "First, playing around with the depth of the network - the depth is defined by the number of functions you add in the init method of the Net class.\n",
    "\n",
    "**Note that** for 0 hidden layers, we have a regular linear model. \n",
    "\n",
    "Using only one hidden layer, but with sufficient width, ensures that the network is a Universal Approximator (can approximate any function). \n",
    "\n",
    "The activation functions can have a very important impact on the network. It is common practice to choose the same for all layers, except the output layer, which controls the nature of the overall function (net). First, visualize, using TF Playground, the difference in hypothesis (function shape) when changing function. The sigmoid function is historically important, but has near 0 gradient for high absolute values, which makes the gradient vanish. Try to compare performance in MNIST between sigmoid and more recent activation functions like ReLU or tanh.\n",
    "\n",
    "### Learning Rate and Optimizer\n",
    "The learning rate of the gradient descent is a very common and crucial hyperparameter is a lot of ML applications, including Deep Learning.\n",
    "Try tweaking it - you should observe that high values lead to unstable learning, but low values lead to slow learning.\n",
    "\n",
    "Using simply the SGD update w -= alpha*grad_w(J) is often very naive, and prone to stochasticity. Lately, a lot of methods have appeared to try and add momentum, vary the learning rate depending on the specific parameter, etc. In PyTorch, the optimizer is selected using\n",
    "`optimizer = torch.optim.SGD(net.parameters(), lr=0.01)`\n",
    "\n",
    "## Loss and Regularization\n",
    "The most common loss to optimize is simply the Means Squared Error, (h(x) - y)² - trying to minimize the distance between your prediction and the ground truth. However, other measures can be used. After documenting yourself, try comparing MSE with the Cross Entropy Loss in PyTorch on the MNIST problem.\n",
    "\n",
    "A very common cause for overfitting is that the network weights explode - if you try to fit 10 2D points with a 10 degree polynomial, you will often find very high weight values that lead to severe overfitting, rather than truly trying to find the trend.\n",
    "In order to prevent weight explosion, *L2 Regularization* add a soft constraint to the loss under the form of a lambda*||w||\\_2 term (L1 Reg uses norm 1). This way, the optimizer tries to solve the task using weights as small as possible. Conveniently in PyTorch, as you can see in the doc, the Regularization (\"weight decay\") is an optional argument to the optimizer!\n",
    "\n",
    "## Batch size\n",
    "The reason the optimizer is called Stochastic Gradient Descent, as opposed to usual Gradient Descent, is because we only use subsets (batches) of the training data instead of the whole thing at once, acting like a sample in a stochastic computation. This was found to lead to great gains in wall-clock performance, since we don't have to loop over the whole dataset, which might be millions of entries big. In particular, this has lead to huge gains in efficiency thanks to GPUs, massively excelling in parallelized computing but with limited RAM that cannot hold the whole dataset at once.\n",
    "\n",
    "## Dropout\n",
    "The neurons of a neural network are extremely heavily dependent on the values of the previous neurons - each of the inputs can have a drastic impact on the output. This is often a major culprit for overfitting, where the neurons cannot generalize properly because the new testing distribution looks very different from the training distribution.\n",
    "In order to prevent these heavy dependencies, one of the core techniques of Deep Learning was invented: Dropout. This simply means that in training, each neuron has some probability to be turned off altogether! This means that the downstream neurons need to be flexible enough to adapt to all kinds of changes in input; no rely too heavily on a single input, but rather find valuable information in all of it.\n",
    "Dropout can conveniently be seen as an [https://pytorch.org/docs/stable/nn.html#dropout-layers](additional layer), that you can add after any layer (except the output), with a constant giving the probability to turn the neuron off.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 6)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['quality'] = str(dataset['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(dataset['quality'].values)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "labels = le.transform(dataset['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(dataset[features].values,\n",
    "                                                    labels, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to observe that, for a very wide layer, the network overfits to the testing data (...leading to a suspicious wine quality accuracy). The width can be controlled by changing how many inputs and outputs each intermediate function (i.e. hidden layer) takes in and gives out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.data)\n",
    "\n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "\n",
    "print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **TODO** </span> How can you identify overfitting network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try now to compare your overfitting network with a deeper, but less wide network. Hopefully, you get stronger results at test time: a deeper network can help generalize better. You can test the limits of this by using a much deeper network: you will overfit again! A lot of weights often means great expressiveness, which sometimes hurts generelization.\n",
    "To observe overfitting in TF Playground, try using the maximal network depth and width!\n",
    "\n",
    "<span style=\"color:blue\"> **TODO** </span> Reinitilize a narrower network and lower number of epochs. re-run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range( **TODO** ):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.data)\n",
    "\n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "\n",
    "print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. CNN\n",
    "Welcome to third part of tutorial. <br>\n",
    "CNNs are Convolutional Neural Networks, Due to limitations of MLP CNNs were born. <br>\n",
    "Now it's time to play. <br>\n",
    "I would like to remind you. It's very important that you develop understanding of **MLP** and **CNNs** as they will be primary building blocks of DRL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # convolution layer 1\n",
    "        x = F.relu(x) # activation function\n",
    "        x = self.conv2(x) # convolution layer 2\n",
    "        x = F.relu(x) # activation function\n",
    "        x = F.max_pool2d(x, 2) # polling layer\n",
    "        x = self.dropout1(x) # drop out\n",
    "        x = torch.flatten(x, 1) # flatten\n",
    "        x = self.fc1(x) # fully connected\n",
    "        x = F.relu(x) # activation function\n",
    "        x = self.dropout2(x) # drop out\n",
    "        x = self.fc2(x) # fully connected\n",
    "        output = F.log_softmax(x, dim=1)  \n",
    "        return output\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    \"\"\"\n",
    "    Function to train the model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: instance of model.\n",
    "    \n",
    "    device: GPU/CPU\n",
    "        determined by pytorch if you have cuda installed. by default CPU\n",
    "        \n",
    "    train_loader: DataLoader\n",
    "        instance to load training data, useful to form batches and do data transformation.\n",
    "    \n",
    "    optimiser: optimiser\n",
    "    \n",
    "    epoch: int\n",
    "    \n",
    "    log_interval: int\n",
    "        the interval with which you want to log your metrices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_loss: float\n",
    "    \n",
    "    train_accuracy: float\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = list()\n",
    "    train_accuracy = list()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            accuracy =100. * correct / len(train_loader.dataset)\n",
    "            train_accuracy.append(accuracy)\n",
    "            train_loss.append(loss.item())\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader)))\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    \"\"\"\n",
    "    Function to test the model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: instance of model.\n",
    "    \n",
    "    device: GPU/CPU\n",
    "        determined by pytorch if you have cuda installed. by default CPU\n",
    "        \n",
    "    test_loader: DataLoader\n",
    "        instance to load testing data, useful to form batches and do data transformation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    test_loss: float\n",
    "    \n",
    "    test_accuracy: float\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(batch_size, test_batch_size, epochs, lr, gamma, seed, file_name):\n",
    "    # Training settings\n",
    "    batch_size=batch_size\n",
    "    test_batch_size=test_batch_size\n",
    "    epochs=epochs\n",
    "    lr=lr\n",
    "    gamma=gamma\n",
    "    no_cuda=False\n",
    "    seed=seed\n",
    "    log_interval=1\n",
    "    save_model=False\n",
    "    test_loss_array = list()\n",
    "    train_loss_array = list()\n",
    "    test_accuracy_array = list()\n",
    "    train_accuracy_array = list()\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # set device for training (cpu/gpu)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    \n",
    "    # wrap data in class and apply transformations\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    # declare model and copy it's instance to device\n",
    "    model = Net().to(device)\n",
    "    \n",
    "    # declare optimiser.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    # \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss , train_accuracy = train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        test_loss_array.append(test_loss)\n",
    "        test_accuracy_array.append(test_accuracy)\n",
    "        train_loss_array.append(np.mean(train_loss))\n",
    "        train_accuracy_array.append(np.mean(train_accuracy))\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_count = range(1, len(test_loss_array) + 1)\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, test_loss_array, 'r--')\n",
    "    plt.plot(epoch_count, train_loss_array, 'b-')\n",
    "    plt.legend(['Test Loss', 'Train Loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show();\n",
    "    \n",
    "    plt.plot(epoch_count, test_accuracy_array, 'r--')\n",
    "    plt.plot(epoch_count, train_accuracy_array, 'b-')\n",
    "    plt.legend(['Test Accuracy', 'Train Accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show();\n",
    "    \n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> **TODO** </span> Run the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(batch_size=64, test_batch_size=64, epochs=10, lr=0.2, gamma=0.7, seed=1, file_name=\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> **TODO** </span> Reinitilize optimizer to Adam.\n",
    "\n",
    "<span style=\"color:red\"> **TODO** </span>  How does this impact learning? Explain briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(batch_size=64, test_batch_size=64, epochs=10, lr=0.2, gamma=0.7, seed=1, file_name=\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> **TODO** </span> Reinitilize size of the batch (increase and decrease).\n",
    "\n",
    "<span style=\"color:red\"> **TODO** </span>  How does this impact learning? Explain briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(batch_size=, test_batch_size=64, epochs=10, lr=0.2, gamma=0.7, seed=1, file_name=\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(batch_size=, test_batch_size=64, epochs=10, lr=0.2, gamma=0.7, seed=1, file_name=\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
